{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "print(threading.active_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<_MainThread(MainThread, started 548259434512)>, <Thread(Thread-2, started daemon 548190073328)>, <Heartbeat(Thread-3, started daemon 548181680624)>, <HistorySavingThread(IPythonHistorySavingThread, started 548156502512)>, <ParentPollerUnix(Thread-1, started daemon 547809653232)>]\n"
     ]
    }
   ],
   "source": [
    "print(threading.enumerate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jetbot import Robot\n",
    "from jetbot import Camera\n",
    "from jetbot import bgr8_to_jpeg\n",
    "\n",
    "from time import sleep\n",
    "import ipywidgets.widgets as widgets\n",
    "import traitlets\n",
    "\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import atexit\n",
    "import cv2\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera2(SingletonConfigurable):\n",
    "    \n",
    "    value = traitlets.Any()\n",
    "    \n",
    "    # config\n",
    "    width = traitlets.Integer(default_value=224).tag(config=True)\n",
    "    height = traitlets.Integer(default_value=224).tag(config=True)\n",
    "    fps = traitlets.Integer(default_value=21).tag(config=True)\n",
    "    capture_width = traitlets.Integer(default_value=3280).tag(config=True)\n",
    "    capture_height = traitlets.Integer(default_value=2464).tag(config=True)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.value = np.empty((self.height, self.width, 3), dtype=np.uint8)\n",
    "        super(Camera2, self).__init__(*args, **kwargs)\n",
    "\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self._gst_str(), cv2.CAP_GSTREAMER)\n",
    "\n",
    "            re, image = self.cap.read()\n",
    "\n",
    "            if not re:\n",
    "                raise RuntimeError('Could not read image from camera.')\n",
    "\n",
    "            self.value = image\n",
    "            self.start()\n",
    "        except:\n",
    "            self.stop()\n",
    "            raise RuntimeError(\n",
    "                'Could not initialize camera.  Please see error trace.')\n",
    "\n",
    "        atexit.register(self.stop)\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while True:\n",
    "            re, image = self.cap.read()\n",
    "            if re:\n",
    "                self.value = image\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    def _gst_str(self):\n",
    "        return 'nvarguscamerasrc ! video/x-raw(memory:NVMM), width=%d, height=%d, format=(string)NV12, framerate=(fraction)%d/1 ! nvvidconv ! video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! videoconvert ! appsink' % (\n",
    "                self.capture_width, self.capture_height, self.fps, self.width, self.height)\n",
    "    \n",
    "    def start(self):\n",
    "        if not self.cap.isOpened():\n",
    "            self.cap.open(self._gst_str(), cv2.CAP_GSTREAMER)\n",
    "        if not hasattr(self, 'thread') or not self.thread.isAlive():\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if hasattr(self, 'cap'):\n",
    "            self.cap.release()\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()\n",
    "            \n",
    "    def restart(self):\n",
    "        self.stop()\n",
    "        self.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera2.instance(width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "camW = 640\n",
    "camH = 480\n",
    "camera = Camera2.instance(width=camW, height=camH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROIWidth = camW\n",
    "ROIHeight = 50\n",
    "ROILeftUpX = 0\n",
    "ROILeftUpY = 150\n",
    "# ROILeftUpX = 150\n",
    "# ROILeftUpY = 305\n",
    "ROIRightBottomX = ROILeftUpX + ROIWidth\n",
    "ROIRightBottomY = ROILeftUpY + ROIHeight\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait for 2 seconds...\n",
      "./img/img0.jpg saved\n"
     ]
    }
   ],
   "source": [
    "print(\"wait for 2 seconds...\")\n",
    "# sleep(1)\n",
    "for i in range(1):\n",
    "    img = camera.value\n",
    "    hsvArray = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    markedImageArray = img\n",
    "    cropped = img[ROILeftUpY:ROIRightBottomY, ROILeftUpX:ROIRightBottomX]\n",
    "    croppedHSV = hsvArray[ROILeftUpY:ROIRightBottomY, ROILeftUpX:ROIRightBottomX]\n",
    "    # mark ROI (BGR)\n",
    "    borderWIDTH = 1\n",
    "    # left border\n",
    "    markedImageArray[ROILeftUpY:ROIRightBottomY, ROILeftUpX:ROILeftUpX+borderWIDTH, 0] = 0\n",
    "    markedImageArray[ROILeftUpY:ROIRightBottomY, ROILeftUpX:ROILeftUpX+borderWIDTH, 1] = 0\n",
    "    markedImageArray[ROILeftUpY:ROIRightBottomY, ROILeftUpX:ROILeftUpX+borderWIDTH, 2] = 255\n",
    "    # top border\n",
    "    markedImageArray[ROILeftUpY:ROILeftUpY+borderWIDTH, ROILeftUpX:ROIRightBottomX, 0] = 0\n",
    "    markedImageArray[ROILeftUpY:ROILeftUpY+borderWIDTH, ROILeftUpX:ROIRightBottomX, 1] = 0\n",
    "    markedImageArray[ROILeftUpY:ROILeftUpY+borderWIDTH, ROILeftUpX:ROIRightBottomX, 2] = 255\n",
    "    # right border\n",
    "    markedImageArray[ROILeftUpY:ROIRightBottomY, ROIRightBottomX-borderWIDTH:ROIRightBottomX, 0] = 0\n",
    "    markedImageArray[ROILeftUpY:ROIRightBottomY, ROIRightBottomX-borderWIDTH:ROIRightBottomX, 1] = 0\n",
    "    markedImageArray[ROILeftUpY:ROIRightBottomY, ROIRightBottomX-borderWIDTH:ROIRightBottomX, 2] = 255\n",
    "    # bottom border\n",
    "    markedImageArray[ROIRightBottomY-borderWIDTH:ROIRightBottomY, ROILeftUpX:ROIRightBottomX, 0] = 0\n",
    "    markedImageArray[ROIRightBottomY-borderWIDTH:ROIRightBottomY, ROILeftUpX:ROIRightBottomX, 1] = 0\n",
    "    markedImageArray[ROIRightBottomY-borderWIDTH:ROIRightBottomY, ROILeftUpX:ROIRightBottomX, 2] = 255\n",
    "    \n",
    "    # YELLOW - find column with the most yellow pixels\n",
    "    # Yellow H value of HSV color space: 60 in range of [0,360], 30 in range of [0,180] in openCV\n",
    "    # Yellow Range: H:[25,35] S:[100,255] V:[100,255]\n",
    "    maskYellow = ((20 <= croppedHSV[:,:,0]) & (croppedHSV[:,:,0] <= 40)) \\\n",
    "                    & (croppedHSV[:,:,1] >= 50) & (croppedHSV[:,:,2] >= 50)\n",
    "    yellows = maskYellow.sum(axis=0)\n",
    "    laneYellow = yellows.argmax()\n",
    "    \n",
    "    # WHITE - find column with the most white pixels\n",
    "    # White Range: H:[0,255] S:[0,255] V:[255,255]\n",
    "    # if the saturation is low and the value is high\n",
    "    maskWhite = (croppedHSV[:,:,0] <= 0) \\\n",
    "               & (croppedHSV[:,:,1] <= 0) & (croppedHSV[:,:,2] >= 255)\n",
    "    whites = maskWhite.sum(axis=0)\n",
    "    laneWhite = whites.argmax()\n",
    "    laneWhite = 0\n",
    "    # GREEN - find column with the most green pixels\n",
    "    # Green H value of HSV color space: 120 in range of [0,360], 60 in range of [0,180] in openCV\n",
    "    # Green Range: H:[55,65] S:[100,255] V:[100,255]\n",
    "    maskGreen = (40 <= croppedHSV[:,:,0]) & (croppedHSV[:,:,0] <= 80) \\\n",
    "                    & (croppedHSV[:,:,1] >= 100) & (croppedHSV[:,:,2] >= 100)\n",
    "    greens = maskGreen.sum(axis=0)\n",
    "    laneGreen = greens.argmax()\n",
    "    \n",
    "    # RED - find column with the most red pixels\n",
    "    # Red H value of HSV color space: 0~10 and  in range of [0,360], 60 in range of [0,180] in openCV\n",
    "    # Red Range: H:[55,65] S:[100,255] V:[100,255]\n",
    "    maskRed = (((0 <= croppedHSV[:,:,0]) & (croppedHSV[:,:,0] <= 20)) | \\\n",
    "               ((160 <= croppedHSV[:,:,0]) & (croppedHSV[:,:,0] <= 180))) & \\\n",
    "                (croppedHSV[:,:,1] >= 50) & (croppedHSV[:,:,2] >= 50)\n",
    "    reds = maskRed.sum(axis=0)\n",
    "    laneRed = reds.argmax()\n",
    "\n",
    "    # BLUE\n",
    "    # Blue Range: H:[110,130] S:[50,255] V:[50,255]\n",
    "    maskBlue = ((100 <= croppedHSV[:,:,0]) & (croppedHSV[:,:,0] <= 140)) & \\\n",
    "                (croppedHSV[:,:,1] >= 50) & (croppedHSV[:,:,2] >= 50)\n",
    "    blues = maskBlue.sum(axis=0)\n",
    "    laneBlue = blues.argmax()\n",
    "    \n",
    "    # mark Yellow\n",
    "    yellowColumn = ROILeftUpX + laneYellow\n",
    "    markedImageArray[:,yellowColumn-1:yellowColumn, 0] = 0\n",
    "    markedImageArray[:,yellowColumn-1:yellowColumn, 1] = 255\n",
    "    markedImageArray[:,yellowColumn-1:yellowColumn, 2] = 255\n",
    "\n",
    "    # mark White\n",
    "    whiteColumn = ROILeftUpX + laneWhite\n",
    "    markedImageArray[:,whiteColumn-1:whiteColumn, 0] = 255\n",
    "    markedImageArray[:,whiteColumn-1:whiteColumn, 1] = 255\n",
    "    markedImageArray[:,whiteColumn-1:whiteColumn, 2] = 255\n",
    "\n",
    "    # mark Green\n",
    "    greenColumn = ROILeftUpX + laneGreen\n",
    "    markedImageArray[:,greenColumn-1:greenColumn, 0] = 0\n",
    "    markedImageArray[:,greenColumn-1:greenColumn, 1] = 255\n",
    "    markedImageArray[:,greenColumn-1:greenColumn, 2] = 0\n",
    "    \n",
    "    # mark Red\n",
    "    redColumn = ROILeftUpX + laneRed\n",
    "    markedImageArray[:,redColumn-1:redColumn, 0] = 0\n",
    "    markedImageArray[:,redColumn-1:redColumn, 1] = 0\n",
    "    markedImageArray[:,redColumn-1:redColumn, 2] = 255\n",
    "    \n",
    "    # mark Blue\n",
    "    blueColumn = ROILeftUpX + laneBlue\n",
    "    markedImageArray[:,blueColumn-1:blueColumn, 0] = 255\n",
    "    markedImageArray[:,blueColumn-1:blueColumn, 1] = 0\n",
    "    markedImageArray[:,blueColumn-1:blueColumn, 2] = 0\n",
    "    \n",
    "    prefix = \"./img/img\"\n",
    "    suffix = \".jpg\"\n",
    "#     cv2.imwrite(prefix+str(i)+suffix, camera.value)\n",
    "#     cv2.imwrite(prefix+str(i)+\"crop\"+suffix, cropped)\n",
    "    cv2.imwrite(prefix+str(i)+\"mark\"+suffix, markedImageArray)\n",
    "    cv2.imwrite(prefix+str(i)+\"hsv\"+suffix, croppedHSV)\n",
    "    print(prefix+str(i)+suffix+\" saved\")\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "asf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = croppedHSV[:,:,0].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "869"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 200, 3)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croppedHSV.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  0,  0, ..., 82, 92, 97]),\n",
       " array([ 2,  3,  4, ..., 36, 24, 35]),\n",
       " array([1, 1, 1, ..., 1, 1, 1]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(croppedHSV == np.max(croppedHSV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "croppedHSV[97][35][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img/img0mark.jpg\")\n",
    "cv2.imshow(\"hello\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traitlets\n",
    "from traitlets.config.configurable import SingletonConfigurable\n",
    "import atexit\n",
    "import cv2\n",
    "import threading\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Camera2(SingletonConfigurable):\n",
    "    \n",
    "    value = traitlets.Any()\n",
    "    \n",
    "    # config\n",
    "    width = traitlets.Integer(default_value=224).tag(config=True)\n",
    "    height = traitlets.Integer(default_value=224).tag(config=True)\n",
    "    fps = traitlets.Integer(default_value=21).tag(config=True)\n",
    "    capture_width = traitlets.Integer(default_value=3280).tag(config=True)\n",
    "    capture_height = traitlets.Integer(default_value=2464).tag(config=True)\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.value = np.empty((self.height, self.width, 3), dtype=np.uint8)\n",
    "        super(Camera, self).__init__(*args, **kwargs)\n",
    "\n",
    "        try:\n",
    "            self.cap = cv2.VideoCapture(self._gst_str(), cv2.CAP_GSTREAMER)\n",
    "\n",
    "            re, image = self.cap.read()\n",
    "\n",
    "            if not re:\n",
    "                raise RuntimeError('Could not read image from camera.')\n",
    "\n",
    "            self.value = image\n",
    "            self.start()\n",
    "        except:\n",
    "            self.stop()\n",
    "            raise RuntimeError(\n",
    "                'Could not initialize camera.  Please see error trace.')\n",
    "\n",
    "        atexit.register(self.stop)\n",
    "\n",
    "    def _capture_frames(self):\n",
    "        while True:\n",
    "            re, image = self.cap.read()\n",
    "            if re:\n",
    "                self.value = image\n",
    "            else:\n",
    "                break\n",
    "                \n",
    "    def _gst_str(self):\n",
    "        return 'nvarguscamerasrc ! video/x-raw(memory:NVMM), width=%d, height=%d, format=(string)NV12, framerate=(fraction)%d/1 ! nvvidconv ! video/x-raw, width=(int)%d, height=(int)%d, format=(string)BGRx ! videoconvert ! appsink' % (\n",
    "                self.capture_width, self.capture_height, self.fps, self.width, self.height)\n",
    "    \n",
    "    def start(self):\n",
    "        if not self.cap.isOpened():\n",
    "            self.cap.open(self._gst_str(), cv2.CAP_GSTREAMER)\n",
    "        if not hasattr(self, 'thread') or not self.thread.isAlive():\n",
    "            self.thread = threading.Thread(target=self._capture_frames)\n",
    "            self.thread.start()\n",
    "\n",
    "    def stop(self):\n",
    "        if hasattr(self, 'cap'):\n",
    "            self.cap.release()\n",
    "        if hasattr(self, 'thread'):\n",
    "            self.thread.join()\n",
    "            \n",
    "    def restart(self):\n",
    "        self.stop()\n",
    "        self.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Each object must be HasTraits, not <class 'numpy.ndarray'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cab757faa655>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mblocked_slider\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatSlider\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blocked'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'vertical'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcamera_link\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraitlets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcropped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbgr8_to_jpeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidgets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHBox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocked_slider\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, target, transform)\u001b[0m\n\u001b[1;32m    335\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0m_validate_link\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/traitlets/traitlets.py\u001b[0m in \u001b[0;36m_validate_link\u001b[0;34m(*tuples)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrait_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHasTraits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Each object must be HasTraits, not %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtrait_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%r has no trait %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrait_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Each object must be HasTraits, not <class 'numpy.ndarray'>"
     ]
    }
   ],
   "source": [
    "import traitlets\n",
    "from IPython.display import display\n",
    "import ipywidgets.widgets as widgets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=300, height=250)\n",
    "image = widgets.Image(format='jpeg', width=300, height=250)\n",
    "cropped = camera.value[0:30, 0:300]\n",
    "blocked_slider = widgets.FloatSlider(description='blocked', min=0.0, max=1.0, orientation='vertical')\n",
    "\n",
    "camera_link = traitlets.dlink((cropped, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(widgets.HBox([image, blocked_slider]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    r, f = camera.cap.read()\n",
    "    g = cv2.cvtColor(f, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite('./img/image{}.png'.format(i), g)\n",
    "#     sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow('frame', g)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n",
      "image detected\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "/home/nvidia/build_opencv/opencv/modules/highgui/src/window_gtk.cpp:1198: error: (-215) found && \"Can't destroy non-registered window\" in function cvDestroyWindow\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d7fbebad1e75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdestroyWindow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'frame'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'not detected'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: /home/nvidia/build_opencv/opencv/modules/highgui/src/window_gtk.cpp:1198: error: (-215) found && \"Can't destroy non-registered window\" in function cvDestroyWindow\n"
     ]
    }
   ],
   "source": [
    "# while(camera.cap.isOpened()):  # check !\n",
    "#     # capture frame-by-frame\n",
    "#     ret, frame = camera.cap.read()\n",
    "\n",
    "#     if ret: # check ! (some webcam's need a \"warmup\")\n",
    "#         # our operation on frame come here\n",
    "#         gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#         # Display the resulting frame\n",
    "#         cv2.imshow('frame', gray)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyWindow('frame')\n",
    "#     else:\n",
    "#         print('image frame not detected')\n",
    "        \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "# # When everything is done release the capture\n",
    "# camera.cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
